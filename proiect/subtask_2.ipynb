{"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.12.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"colab":{"provenance":[],"gpuType":"V5E1"},"accelerator":"TPU","widgets":{"application/vnd.jupyter.widget-state+json":{"0634df1f4db4405db44d1c2d81cd4773":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_ffa03727082e422ab1605c76b1af2e19","IPY_MODEL_596f8c71cf0047ef83e8df3c6d864aa7","IPY_MODEL_3a31b8c1259640828c78e6198e8b295b"],"layout":"IPY_MODEL_19fbaa3d2228408885c5ed3125fd0288"}},"ffa03727082e422ab1605c76b1af2e19":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_4196d0ff352f4a478ef53069838eb8e6","placeholder":"​","style":"IPY_MODEL_6dd21822f6074ce587b3f5713f977adc","value":"Map: 100%"}},"596f8c71cf0047ef83e8df3c6d864aa7":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_342844f154f3482ea494bc3473a3f576","max":4076,"min":0,"orientation":"horizontal","style":"IPY_MODEL_87cad96fc07e44958d29f43c3c15b065","value":4076}},"3a31b8c1259640828c78e6198e8b295b":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_5d7021b3d2174012a5970d3b8b001dbc","placeholder":"​","style":"IPY_MODEL_a8c515fca3164690b75fd5fea1d5dfb8","value":" 4076/4076 [00:03&lt;00:00, 1084.94 examples/s]"}},"19fbaa3d2228408885c5ed3125fd0288":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"4196d0ff352f4a478ef53069838eb8e6":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"6dd21822f6074ce587b3f5713f977adc":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"342844f154f3482ea494bc3473a3f576":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"87cad96fc07e44958d29f43c3c15b065":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"5d7021b3d2174012a5970d3b8b001dbc":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"a8c515fca3164690b75fd5fea1d5dfb8":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}}}},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceType":"datasetVersion","sourceId":14500774,"datasetId":9212759,"databundleVersionId":15326425}],"dockerImageVersionId":31236,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"pip install transformers","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"970aa8c4","outputId":"2c4c529a-cc1d-495a-df41-ad19d07ea23b","trusted":true,"execution":{"iopub.status.busy":"2026-01-15T19:14:59.768343Z","iopub.execute_input":"2026-01-15T19:14:59.769217Z","iopub.status.idle":"2026-01-15T19:15:03.751211Z","shell.execute_reply.started":"2026-01-15T19:14:59.769183Z","shell.execute_reply":"2026-01-15T19:15:03.750446Z"}},"outputs":[{"name":"stdout","text":"Requirement already satisfied: transformers in /usr/local/lib/python3.12/dist-packages (4.57.1)\nRequirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from transformers) (3.20.1)\nRequirement already satisfied: huggingface-hub<1.0,>=0.34.0 in /usr/local/lib/python3.12/dist-packages (from transformers) (0.36.0)\nRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.12/dist-packages (from transformers) (2.0.2)\nRequirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.12/dist-packages (from transformers) (25.0)\nRequirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.12/dist-packages (from transformers) (6.0.3)\nRequirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.12/dist-packages (from transformers) (2025.11.3)\nRequirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (from transformers) (2.32.5)\nRequirement already satisfied: tokenizers<=0.23.0,>=0.22.0 in /usr/local/lib/python3.12/dist-packages (from transformers) (0.22.1)\nRequirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.12/dist-packages (from transformers) (0.6.2)\nRequirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.12/dist-packages (from transformers) (4.67.1)\nRequirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<1.0,>=0.34.0->transformers) (2025.10.0)\nRequirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<1.0,>=0.34.0->transformers) (4.15.0)\nRequirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<1.0,>=0.34.0->transformers) (1.2.1rc0)\nRequirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests->transformers) (3.4.4)\nRequirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests->transformers) (3.11)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests->transformers) (2.6.2)\nRequirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests->transformers) (2025.11.12)\nNote: you may need to restart the kernel to use updated packages.\n","output_type":"stream"}],"execution_count":2},{"cell_type":"code","source":"import pandas as pd, os\npd.set_option('display.max_colwidth', None)\n\ndata_test1 = pd.read_json(open('/kaggle/input/test-dimabsa-2026/eng_laptop_dev_task1.jsonl', encoding='utf8'), lines=True)\ndata_test2 = pd.read_json(open('/kaggle/input/test-dimabsa-2026/eng_laptop_dev_task2.jsonl', encoding='utf8'), lines=True)\ndata_test3 = pd.read_json(open('/kaggle/input/test-dimabsa-2026/data/eng_laptop_dev_task3.jsonl', encoding='utf8'), lines=True)\ndata_test11 = pd.read_json(open('/kaggle/input/test-dimabsa-2026/eng_restaurant_dev_task1.jsonl', encoding='utf8'), lines=True)\ndata_test21 = pd.read_json(open('/kaggle/input/test-dimabsa-2026/eng_restaurant_dev_task2.jsonl', encoding='utf8'), lines=True)\ndata_test31 = pd.read_json(open('/kaggle/input/test-dimabsa-2026/data/eng_restaurant_dev_task3.jsonl', encoding='utf8'), lines=True)\ndata_test = pd.concat([data_test1, data_test2, data_test3, data_test11, data_test21, data_test31])\n\nFILE_NAME = \"eng_laptop_train_alltasks.jsonl\"\n\nfile_name = os.path.join('/kaggle/input/test-dimabsa-2026/data/', FILE_NAME)\ndata = pd.read_json(open(file_name, encoding='utf8'), lines=True)\n\n\nfile_name = os.path.join('/kaggle/input/test-dimabsa-2026/data/', \"eng_restaurant_train_alltasks.jsonl\")\ndata_extra = pd.read_json(open(file_name, encoding='utf8'), lines=True)\ndata\n","metadata":{"id":"68d1bc9a","colab":{"base_uri":"https://localhost:8080/","height":1000},"outputId":"e5ed9b88-c70f-4448-86d3-3ca023c1506c","trusted":true,"execution":{"iopub.status.busy":"2026-01-15T19:15:03.752819Z","iopub.execute_input":"2026-01-15T19:15:03.753104Z","iopub.status.idle":"2026-01-15T19:15:03.848772Z","shell.execute_reply.started":"2026-01-15T19:15:03.753073Z","shell.execute_reply":"2026-01-15T19:15:03.848067Z"},"collapsed":true,"jupyter":{"outputs_hidden":true}},"outputs":[{"execution_count":3,"output_type":"execute_result","data":{"text/plain":"                          ID  \\\n0          laptop_quad_dev_1   \n1          laptop_quad_dev_2   \n2          laptop_quad_dev_3   \n3          laptop_quad_dev_4   \n4          laptop_quad_dev_5   \n...                      ...   \n4071  laptop_quad_train_2930   \n4072  laptop_quad_train_2931   \n4073  laptop_quad_train_2932   \n4074  laptop_quad_train_2933   \n4075  laptop_quad_train_2934   \n\n                                                                                                                                                                                          Text  \\\n0                                                                                   this unit is ` ` pretty ` ` and stylish , so my high school daughter was attracted to it for that reason .   \n1                                                                                                                 for now i ' m okay with upping the experience & device to 3 out of 5 stars .   \n2                                                                                                                                            seems unlikely but whatever , i ' ll go with it .   \n3                                                                                this version has been my least favorite version i ' ve had for the following reasons listed bellow the pros .   \n4                                                                                                                                                  - biggest disappointment is the track pad .   \n...                                                                                                                                                                                        ...   \n4071                                                                                                                                                       i think the sound could be better .   \n4072  i didn ' t want to spend much on this as it is my first laptop , but i was convinced by a few reviews to upgrade to this model as it has more ram and performs better in several areas .   \n4073                                                                                                                        an awesome product , well built - well worth your time and money .   \n4074                                                                                                                              backlit keyboard is great ; feels sturdy ; fast processing .   \n4075                                                                                                                                                         the keyboard is nice to type on .   \n\n                                                                                                                                                                                                                                                                                                        Quadruplet  \n0                                                                                                            [{'Aspect': 'unit', 'Category': 'LAPTOP#DESIGN_FEATURES', 'Opinion': 'pretty', 'VA': '7.12#7.12'}, {'Aspect': 'unit', 'Category': 'LAPTOP#DESIGN_FEATURES', 'Opinion': 'stylish', 'VA': '7.12#7.12'}]  \n1                                                                                                                                                                                                                       [{'Aspect': 'device', 'Category': 'LAPTOP#GENERAL', 'Opinion': 'NULL', 'VA': '5.50#5.25'}]  \n2                                                                                                                                                                                                                         [{'Aspect': 'NULL', 'Category': 'LAPTOP#GENERAL', 'Opinion': 'NULL', 'VA': '5.00#5.12'}]  \n3                                                                                                                                                                                                            [{'Aspect': 'version', 'Category': 'LAPTOP#GENERAL', 'Opinion': 'least favorite', 'VA': '3.30#6.60'}]  \n4                                                                                                                                                                                                        [{'Aspect': 'track pad', 'Category': 'HARDWARE#GENERAL', 'Opinion': 'disappointment', 'VA': '2.50#6.00'}]  \n...                                                                                                                                                                                                                                                                                                            ...  \n4071                                                                                                                                                                                [{'Aspect': 'sound', 'Category': 'MULTIMEDIA_DEVICES#OPERATION_PERFORMANCE', 'Opinion': 'could be better', 'VA': '4.17#5.50'}]  \n4072                                                                                                                                                                                                  [{'Aspect': 'performs', 'Category': 'LAPTOP#OPERATION_PERFORMANCE', 'Opinion': 'better', 'VA': '7.00#6.88'}]  \n4073              [{'Aspect': 'product', 'Category': 'LAPTOP#GENERAL', 'Opinion': 'awesome', 'VA': '7.50#7.50'}, {'Aspect': 'product', 'Category': 'LAPTOP#QUALITY', 'Opinion': 'well built', 'VA': '6.83#7.00'}, {'Aspect': 'product', 'Category': 'LAPTOP#QUALITY', 'Opinion': 'well worth', 'VA': '7.00#7.17'}]  \n4074  [{'Aspect': 'backlit keyboard', 'Category': 'KEYBOARD#GENERAL', 'Opinion': 'great', 'VA': '7.67#7.83'}, {'Aspect': 'NULL', 'Category': 'LAPTOP#DESIGN_FEATURES', 'Opinion': 'sturdy', 'VA': '7.83#8.17'}, {'Aspect': 'NULL', 'Category': 'CPU#OPERATION_PERFORMANCE', 'Opinion': 'fast', 'VA': '8.00#8.33'}]  \n4075                                                                                                                                                                                                  [{'Aspect': 'keyboard', 'Category': 'KEYBOARD#OPERATION_PERFORMANCE', 'Opinion': 'nice', 'VA': '7.00#7.00'}]  \n\n[4076 rows x 3 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>ID</th>\n      <th>Text</th>\n      <th>Quadruplet</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>laptop_quad_dev_1</td>\n      <td>this unit is ` ` pretty ` ` and stylish , so my high school daughter was attracted to it for that reason .</td>\n      <td>[{'Aspect': 'unit', 'Category': 'LAPTOP#DESIGN_FEATURES', 'Opinion': 'pretty', 'VA': '7.12#7.12'}, {'Aspect': 'unit', 'Category': 'LAPTOP#DESIGN_FEATURES', 'Opinion': 'stylish', 'VA': '7.12#7.12'}]</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>laptop_quad_dev_2</td>\n      <td>for now i ' m okay with upping the experience &amp; device to 3 out of 5 stars .</td>\n      <td>[{'Aspect': 'device', 'Category': 'LAPTOP#GENERAL', 'Opinion': 'NULL', 'VA': '5.50#5.25'}]</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>laptop_quad_dev_3</td>\n      <td>seems unlikely but whatever , i ' ll go with it .</td>\n      <td>[{'Aspect': 'NULL', 'Category': 'LAPTOP#GENERAL', 'Opinion': 'NULL', 'VA': '5.00#5.12'}]</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>laptop_quad_dev_4</td>\n      <td>this version has been my least favorite version i ' ve had for the following reasons listed bellow the pros .</td>\n      <td>[{'Aspect': 'version', 'Category': 'LAPTOP#GENERAL', 'Opinion': 'least favorite', 'VA': '3.30#6.60'}]</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>laptop_quad_dev_5</td>\n      <td>- biggest disappointment is the track pad .</td>\n      <td>[{'Aspect': 'track pad', 'Category': 'HARDWARE#GENERAL', 'Opinion': 'disappointment', 'VA': '2.50#6.00'}]</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>4071</th>\n      <td>laptop_quad_train_2930</td>\n      <td>i think the sound could be better .</td>\n      <td>[{'Aspect': 'sound', 'Category': 'MULTIMEDIA_DEVICES#OPERATION_PERFORMANCE', 'Opinion': 'could be better', 'VA': '4.17#5.50'}]</td>\n    </tr>\n    <tr>\n      <th>4072</th>\n      <td>laptop_quad_train_2931</td>\n      <td>i didn ' t want to spend much on this as it is my first laptop , but i was convinced by a few reviews to upgrade to this model as it has more ram and performs better in several areas .</td>\n      <td>[{'Aspect': 'performs', 'Category': 'LAPTOP#OPERATION_PERFORMANCE', 'Opinion': 'better', 'VA': '7.00#6.88'}]</td>\n    </tr>\n    <tr>\n      <th>4073</th>\n      <td>laptop_quad_train_2932</td>\n      <td>an awesome product , well built - well worth your time and money .</td>\n      <td>[{'Aspect': 'product', 'Category': 'LAPTOP#GENERAL', 'Opinion': 'awesome', 'VA': '7.50#7.50'}, {'Aspect': 'product', 'Category': 'LAPTOP#QUALITY', 'Opinion': 'well built', 'VA': '6.83#7.00'}, {'Aspect': 'product', 'Category': 'LAPTOP#QUALITY', 'Opinion': 'well worth', 'VA': '7.00#7.17'}]</td>\n    </tr>\n    <tr>\n      <th>4074</th>\n      <td>laptop_quad_train_2933</td>\n      <td>backlit keyboard is great ; feels sturdy ; fast processing .</td>\n      <td>[{'Aspect': 'backlit keyboard', 'Category': 'KEYBOARD#GENERAL', 'Opinion': 'great', 'VA': '7.67#7.83'}, {'Aspect': 'NULL', 'Category': 'LAPTOP#DESIGN_FEATURES', 'Opinion': 'sturdy', 'VA': '7.83#8.17'}, {'Aspect': 'NULL', 'Category': 'CPU#OPERATION_PERFORMANCE', 'Opinion': 'fast', 'VA': '8.00#8.33'}]</td>\n    </tr>\n    <tr>\n      <th>4075</th>\n      <td>laptop_quad_train_2934</td>\n      <td>the keyboard is nice to type on .</td>\n      <td>[{'Aspect': 'keyboard', 'Category': 'KEYBOARD#OPERATION_PERFORMANCE', 'Opinion': 'nice', 'VA': '7.00#7.00'}]</td>\n    </tr>\n  </tbody>\n</table>\n<p>4076 rows × 3 columns</p>\n</div>"},"metadata":{}}],"execution_count":3},{"cell_type":"markdown","source":"## Prepare Seq2Seq Data\n\n### Subtask:\nTransform the loaded dataset into a seq2seq format. This involves converting each sentence's quadruplets into a target string of aspect-opinion pairs (e.g., 'aspect1#opinion1|aspect2#opinion2'), suitable for a seq2seq model. Handle cases where aspects or opinions are 'NULL'.\n","metadata":{"id":"fbaa1291"}},{"cell_type":"code","source":"def process_quadruplets_to_target_string(quadruplets):\n    target_parts = []\n    for q in quadruplets:\n        aspect = q.get('Aspect', 'NULL')\n        opinion = q.get('Opinion', 'NULL')\n\n        target_parts.append(f\"{aspect}#{opinion}|\")\n\n    return ''.join(target_parts)\n\n# Apply the function to create the 'TargetString' column\ndata['TargetString'] = data['Quadruplet'].apply(process_quadruplets_to_target_string)\ndata_extra['TargetString'] = data_extra['Quadruplet'].apply(process_quadruplets_to_target_string)\n\n# Display the first few rows with the new 'TargetString' column\ndisplay(data[['Text', 'Quadruplet', 'TargetString']].head())","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":397},"id":"0d0ccc8a","outputId":"9bb2afff-d453-47f5-a72a-c76ab5e8f8f1","trusted":true,"execution":{"iopub.status.busy":"2026-01-15T19:15:08.347419Z","iopub.execute_input":"2026-01-15T19:15:08.347702Z","iopub.status.idle":"2026-01-15T19:15:08.366427Z","shell.execute_reply.started":"2026-01-15T19:15:08.347672Z","shell.execute_reply":"2026-01-15T19:15:08.365792Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"                                                                                                            Text  \\\n0     this unit is ` ` pretty ` ` and stylish , so my high school daughter was attracted to it for that reason .   \n1                                   for now i ' m okay with upping the experience & device to 3 out of 5 stars .   \n2                                                              seems unlikely but whatever , i ' ll go with it .   \n3  this version has been my least favorite version i ' ve had for the following reasons listed bellow the pros .   \n4                                                                    - biggest disappointment is the track pad .   \n\n                                                                                                                                                                                              Quadruplet  \\\n0  [{'Aspect': 'unit', 'Category': 'LAPTOP#DESIGN_FEATURES', 'Opinion': 'pretty', 'VA': '7.12#7.12'}, {'Aspect': 'unit', 'Category': 'LAPTOP#DESIGN_FEATURES', 'Opinion': 'stylish', 'VA': '7.12#7.12'}]   \n1                                                                                                             [{'Aspect': 'device', 'Category': 'LAPTOP#GENERAL', 'Opinion': 'NULL', 'VA': '5.50#5.25'}]   \n2                                                                                                               [{'Aspect': 'NULL', 'Category': 'LAPTOP#GENERAL', 'Opinion': 'NULL', 'VA': '5.00#5.12'}]   \n3                                                                                                  [{'Aspect': 'version', 'Category': 'LAPTOP#GENERAL', 'Opinion': 'least favorite', 'VA': '3.30#6.60'}]   \n4                                                                                              [{'Aspect': 'track pad', 'Category': 'HARDWARE#GENERAL', 'Opinion': 'disappointment', 'VA': '2.50#6.00'}]   \n\n                TargetString  \n0  unit#pretty|unit#stylish|  \n1               device#NULL|  \n2                 NULL#NULL|  \n3    version#least favorite|  \n4  track pad#disappointment|  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Text</th>\n      <th>Quadruplet</th>\n      <th>TargetString</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>this unit is ` ` pretty ` ` and stylish , so my high school daughter was attracted to it for that reason .</td>\n      <td>[{'Aspect': 'unit', 'Category': 'LAPTOP#DESIGN_FEATURES', 'Opinion': 'pretty', 'VA': '7.12#7.12'}, {'Aspect': 'unit', 'Category': 'LAPTOP#DESIGN_FEATURES', 'Opinion': 'stylish', 'VA': '7.12#7.12'}]</td>\n      <td>unit#pretty|unit#stylish|</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>for now i ' m okay with upping the experience &amp; device to 3 out of 5 stars .</td>\n      <td>[{'Aspect': 'device', 'Category': 'LAPTOP#GENERAL', 'Opinion': 'NULL', 'VA': '5.50#5.25'}]</td>\n      <td>device#NULL|</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>seems unlikely but whatever , i ' ll go with it .</td>\n      <td>[{'Aspect': 'NULL', 'Category': 'LAPTOP#GENERAL', 'Opinion': 'NULL', 'VA': '5.00#5.12'}]</td>\n      <td>NULL#NULL|</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>this version has been my least favorite version i ' ve had for the following reasons listed bellow the pros .</td>\n      <td>[{'Aspect': 'version', 'Category': 'LAPTOP#GENERAL', 'Opinion': 'least favorite', 'VA': '3.30#6.60'}]</td>\n      <td>version#least favorite|</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>- biggest disappointment is the track pad .</td>\n      <td>[{'Aspect': 'track pad', 'Category': 'HARDWARE#GENERAL', 'Opinion': 'disappointment', 'VA': '2.50#6.00'}]</td>\n      <td>track pad#disappointment|</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}],"execution_count":4},{"cell_type":"markdown","source":"## Initialize Tokenizer and Model\n\n### Subtask:\nLoad a pre-trained tokenizer (e.g., from T5 or BART) and an appropriate encoder-decoder model from the `transformers` library. Configure the tokenizer for both input text and target sequences.\n","metadata":{"id":"502e3cc3"}},{"cell_type":"code","source":"from transformers import AutoTokenizer, AutoModelForSeq2SeqLM\nimport os\n# Choose a pre-trained model checkpoint\nBATCH_SIZE = 4\nEPOCHS=25\nMODEL_NAME = 'model_t5_25'\nMODEL_CHECKPOINT = f'/kaggle/working/{MODEL_NAME}' if os.path.exists(f'/kaggle/working/{MODEL_NAME}') else 't5-base'\n# Initialize the tokenizer\ntokenizer = AutoTokenizer.from_pretrained(MODEL_CHECKPOINT)\nprint(f\"Tokenizer '{MODEL_CHECKPOINT}' loaded successfully.\")\n\n# Initialize the Seq2Seq model\nmodel = AutoModelForSeq2SeqLM.from_pretrained(MODEL_CHECKPOINT)\nprint(f\"Model '{MODEL_CHECKPOINT}' loaded successfully.\")","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"16dc6ce6","outputId":"a661def5-8d92-41fc-d582-ffd04167b90a","trusted":true,"execution":{"iopub.status.busy":"2026-01-15T19:15:14.471618Z","iopub.execute_input":"2026-01-15T19:15:14.471911Z","iopub.status.idle":"2026-01-15T19:15:40.146766Z","shell.execute_reply.started":"2026-01-15T19:15:14.471884Z","shell.execute_reply":"2026-01-15T19:15:40.145922Z"}},"outputs":[{"name":"stdout","text":"Tokenizer '/kaggle/working/model_t5_25' loaded successfully.\n","output_type":"stream"},{"name":"stderr","text":"2026-01-15 19:15:27.007083: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\nWARNING: All log messages before absl::InitializeLog() is called are written to STDERR\nE0000 00:00:1768504527.177993      55 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\nE0000 00:00:1768504527.225455      55 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\nW0000 00:00:1768504527.636744      55 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\nW0000 00:00:1768504527.636776      55 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\nW0000 00:00:1768504527.636780      55 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\nW0000 00:00:1768504527.636782      55 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n","output_type":"stream"},{"name":"stdout","text":"Model '/kaggle/working/model_t5_25' loaded successfully.\n","output_type":"stream"}],"execution_count":5},{"cell_type":"code","source":"def tokenize_function(examples):\n    model_inputs = tokenizer(examples['Text'], max_length=512, truncation=True, padding=\"max_length\")\n    # Setup the tokenizer for targets\n    if 'TargetString' in examples.keys():\n        with tokenizer.as_target_tokenizer():\n            labels = tokenizer(examples['TargetString'], max_length=512, truncation=True, padding=\"max_length\")\n    \n        model_inputs['labels'] = labels['input_ids']\n    return model_inputs\n\n# Apply the tokenization function to the data. We'll convert the pandas DataFrame to a Hugging Face Dataset first.\nfrom datasets import Dataset\n\nhf_dataset = Dataset.from_pandas(data)\ntokenized_data = hf_dataset.map(tokenize_function, batched=True)\nhf_dataset_extra = Dataset.from_pandas(data_extra)\ntokenized_data_extra = hf_dataset_extra.map(tokenize_function, batched=True)\n\n\nhf_dataset_test = Dataset.from_pandas(data_test)\ntokenized_data_test = hf_dataset_test.map(tokenize_function, batched=True)\n\nfrom transformers import DataCollatorForSeq2Seq\n\n# Initialize the data collator\ndata_collator = DataCollatorForSeq2Seq(tokenizer=tokenizer, model=model)\n\nfrom torch.utils.data import DataLoader\nfrom datasets import concatenate_datasets\n\n# Split the tokenized_data into training and evaluation sets\ntrain_test_split_dataset = tokenized_data.train_test_split(test_size=0.3, train_size=0.7, seed=42)\n\ntrain_dataset = concatenate_datasets([train_test_split_dataset['train'], tokenized_data_extra])\neval_dataset = train_test_split_dataset['test']\ntest_dataset = tokenized_data_test\n\nprint(f\"Training dataset size: {len(train_dataset)}\")\nprint(f\"Evaluation dataset size: {len(eval_dataset)}\")\nprint(f\"Test dataset size: {len(test_dataset)}\")\n\n# Create DataLoader instances\ntrain_dataloader = DataLoader(\n    train_dataset,\n    shuffle=True,\n    batch_size=BATCH_SIZE,\n    collate_fn=data_collator\n)\n\neval_dataloader = DataLoader(\n    eval_dataset,\n    shuffle=False,\n    batch_size=BATCH_SIZE,\n    collate_fn=data_collator\n)\n\ntest_dataloader = DataLoader(\n    test_dataset,\n    shuffle=False,\n    batch_size=BATCH_SIZE,\n    collate_fn=data_collator\n)\n\nprint(f\"Train DataLoader created with batch size: {BATCH_SIZE}\")\nprint(f\"Evaluation DataLoader created with batch size: {BATCH_SIZE}\")\nprint(f\"Test DataLoader created with batch size: {BATCH_SIZE}\")","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":260,"referenced_widgets":["0634df1f4db4405db44d1c2d81cd4773","ffa03727082e422ab1605c76b1af2e19","596f8c71cf0047ef83e8df3c6d864aa7","3a31b8c1259640828c78e6198e8b295b","19fbaa3d2228408885c5ed3125fd0288","4196d0ff352f4a478ef53069838eb8e6","6dd21822f6074ce587b3f5713f977adc","342844f154f3482ea494bc3473a3f576","87cad96fc07e44958d29f43c3c15b065","5d7021b3d2174012a5970d3b8b001dbc","a8c515fca3164690b75fd5fea1d5dfb8"]},"id":"504720dd","outputId":"78c8ba8b-fdf2-414a-c33f-18e20644889d","trusted":true,"execution":{"iopub.status.busy":"2026-01-15T19:15:40.148200Z","iopub.execute_input":"2026-01-15T19:15:40.148901Z","iopub.status.idle":"2026-01-15T19:15:43.581002Z","shell.execute_reply.started":"2026-01-15T19:15:40.148860Z","shell.execute_reply":"2026-01-15T19:15:43.580410Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/4076 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"3d5cb97462d047679b5356310fdfb782"}},"metadata":{}},{"name":"stderr","text":"/usr/local/lib/python3.12/dist-packages/transformers/tokenization_utils_base.py:4034: UserWarning: `as_target_tokenizer` is deprecated and will be removed in v5 of Transformers. You can tokenize your labels by using the argument `text_target` of the regular `__call__` method (either in the same call as your input texts if you use the same keyword arguments, or in a separate call.\n  warnings.warn(\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/2284 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"41d504dd69f949288eda9948a92b9abc"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/1200 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"08725b2f45c5402d93ad722ce7317164"}},"metadata":{}},{"name":"stdout","text":"Training dataset size: 5137\nEvaluation dataset size: 1223\nTest dataset size: 1200\nTrain DataLoader created with batch size: 4\nEvaluation DataLoader created with batch size: 4\nTest DataLoader created with batch size: 4\n","output_type":"stream"}],"execution_count":6},{"cell_type":"code","source":"import pandas as pd, regex as re, numpy as np, polars as pl\ndef postprocess(dataframe, stats):\n\ts = 0\n\tfor index, row in dataframe.iterrows():\n\t\tif any((quad['Aspect'] not in row['Text'] and quad['Aspect'] != 'NULL') or (quad['Opinion'] not in row['Text'] and quad['Opinion'] != 'NULL') for quad in row['Quadruplets']):\n\t\t\tp = True\n\t\telse:\n\t\t\ts += 1\n\t\t\tp = False\n\t\tif not p:\n\t\t\tcontinue\n\t\tfor quad in row['Quadruplets']:\n\t\t\tif quad['Aspect'] not in row['Text'] and quad['Aspect'] != 'NULL':\n\t\t\t\t# Incomplete NULL tag\n\t\t\t\tif quad['Aspect'] in 'NULL':\n\t\t\t\t\tquad['Aspect'] = 'NULL'\n\t\t\t\t# Case sensitivity\n\t\t\t\tif quad['Aspect'].lower() in row['Text'].lower():\n\t\t\t\t\tmatches = re.findall(re.escape(quad['Aspect']), row['Text'], flags=re.IGNORECASE)\n\t\t\t\t\tif matches:\n\t\t\t\t\t\tquad['Aspect'] = matches[0]\n\t\t\t\t\t\tstats['aspect_case'] += 1\n\t\t\tif quad['Opinion'] not in row['Text'] and quad['Opinion'] != 'NULL':\n\t\t\t\t# Incomplete NULL tag\n\t\t\t\tif quad['Aspect'] in 'NULL':\n\t\t\t\t\tquad['Aspect'] = 'NULL'\n\t\t\t\telse:\n\t\t\t\t\tif re.match('^not ', quad['Opinion']) and f\"n\\'t {quad['Opinion'][4:]}\" in row['Text']:\n\t\t\t\t\t\tquad['Opinion'] = f'\\'t {quad[\"Opinion\"][4:]}'\n\t\t\t\t\t\tstats['opinion_negation'] += 1\n\t\t\t\t\t# Case sensitivity\n\t\t\t\t\tif quad['Opinion'].lower() in row['Text'].lower():\n\t\t\t\t\t\tmatches = re.findall(re.escape(quad['Opinion']), row['Text'], flags=re.IGNORECASE)\n\t\t\t\t\t\tif matches:\n\t\t\t\t\t\t\tquad['Opinion'] = matches[0]\n\t\t\t\t\t\t\tstats['opinion_case'] += 1\n\treturn dataframe\n\ndef raw_text_to_quads(text):\n\tts = text.split('|')\n\tquads = []\n\tfor t in ts:\n\t\tif len(t) > 0 and '#' in t:\n\t\t\t\tquads.append({'Aspect': t.split('#')[0], 'Opinion': t.split('#')[1]})\n\treturn quads\n\ndef postprocess_raw(output, innputs, stats):\n\tquads = raw_text_to_quads(output)\n\tfor quad, innput in zip(quads, innputs):\n\t\tif quad['Aspect'] not in innput and quad['Aspect'] != 'NULL':\n\t\t\t# Case sensitivity\n\t\t\tif quad['Aspect'].lower() in innput.lower():\n\t\t\t\tmatches = re.findall(re.escape(quad['Aspect']), innput, flags=re.IGNORECASE)\n\t\t\t\tif matches:\n\t\t\t\t\tquad['Aspect'] = matches[0]\n\t\t\t\t\tstats['aspect_case'] += 1\n\t\t\t# Incomplete NULL tag\n\t\t\telif quad['Aspect'] in 'NULL':\n\t\t\t\tquad['Aspect'] = 'NULL'\n\t\tif quad['Opinion'] not in innput and quad['Opinion'] != 'NULL':\n\t\t\t# Case sensitivity\n\t\t\tif quad['Opinion'].lower() in innput.lower():\n\t\t\t\tmatches = re.findall(re.escape(quad['Opinion']), innput, flags=re.IGNORECASE)\n\t\t\t\tif matches:\n\t\t\t\t\tquad['Opinion'] = matches[0]\n\t\t\t\t\tstats['opinion_case'] += 1\n\t\t\t# Incomplete NULL tag\n\t\t\telif quad['Aspect'] in 'NULL':\n\t\t\t\tquad['Aspect'] = 'NULL'\n\t\t\tif re.match('^not ', quad['Opinion']) and f\"n\\'t {quad['Opinion'][4:]}\" in innput:\n\t\t\t\tquad['Opinion'] = f'\\'t {quad[\"Opinion\"][4:]}'\n\t\t\t\tstats['opinion_negation'] += 1\n\n\tout = process_quadruplets_to_target_string(quads)\n\treturn out\n\ndef label_ids_to_text(label_ids, tokenizer):\n\tlabel_ids = np.where(label_ids != -100, label_ids, tokenizer.pad_token_id)\n\tdecoded_text = tokenizer.batch_decode(label_ids, skip_special_tokens=True)\n\treturn decoded_text\n\ndef compute_pair_accuracy(pred_texts, label_texts):\n\tcorrect = 0\n\ttotal = 0\n\ttot_pred = 1\n\tcorrect_pred = 0\n\n\tfor pred, label in zip(pred_texts, label_texts):\n\t\tpred_pairs = raw_text_to_quads(pred)\n\t\tlabel_pairs = raw_text_to_quads(label)\n\n\t\tcorrect_now = 0\n\t\tfor l in label_pairs:\n\t\t\tif len([x for x in pred_pairs if x['Aspect'] == l['Aspect'] and x['Opinion'] == l['Opinion']]):\n\t\t\t\tcorrect_now += 1\n\n\t\ttotal += len(label_pairs)\n\t\tcorrect += correct_now\n\t\ttot_pred += len(pred_pairs)\n\t\tcorrect_pred += correct_now\n\n\treturn (correct / total, correct_pred / tot_pred)\n\ndef compute_pair_precision_recall(pred_texts, label_texts):\n    tp = 0  # True positives\n    fp = 0  # False positives\n    fn = 0  # False negatives\n    total_labels = 0  # Total labels in the ground truth\n\n    # Loop through each prediction and ground truth pair\n    for pred, label in zip(pred_texts, label_texts):\n        pred_pairs = raw_text_to_quads(pred)  # Predicted aspect-opinion pairs\n        label_pairs = raw_text_to_quads(label)  # Ground truth aspect-opinion pairs\n\n        # Count true positives and false positives\n        for l in label_pairs:\n            if len([x for x in pred_pairs if x['Aspect'] == l['Aspect'] and x['Opinion'] == l['Opinion']]):\n                tp += 1  # Correct prediction for this label pair\n            else:\n                fn += 1  # Missed prediction for this label pair\n\n        # Count false positives\n        for p in pred_pairs:\n            if not any(l['Aspect'] == p['Aspect'] and l['Opinion'] == p['Opinion'] for l in label_pairs):\n                fp += 1  # Incorrect prediction (false positive)\n\n        total_labels += len(label_pairs)\n\n    # Calculate precision and recall\n    precision = tp / (tp + fp) if (tp + fp) > 0 else 0\n    recall = tp / (tp + fn) if (tp + fn) > 0 else 0\n\n    return precision, recall\n\ndef compute_metrics(eval_preds):\n\tpreds, labels = eval_preds\n\tinnputs = [\n\t\ttext for text, labelss in zip(eval_dataset[\"Text\"], eval_dataset[\"labels\"])\n\t\tif labelss in labels\n\t]\n\n\tif isinstance(preds, tuple):\n\t\tpreds = preds[0]\n\n\tdecoded_preds = label_ids_to_text(preds, tokenizer)\n\tdecoded_labels = label_ids_to_text(labels, tokenizer)\n\n\t# ---- RAW METRIC ----\n\traw_acc = compute_pair_precision_recall(\n\t\tdecoded_preds,\n\t\tdecoded_labels\n\t)\n\n\t# ---- POSTPROCESSED METRIC ----\n\tstats = {'aspect_case': 0, 'opinion_case': 0, 'opinion_negation': 0}\n\tpost_preds = [postprocess_raw(p, innputs, stats) for p in decoded_preds]\n\n\tpost_acc = compute_pair_precision_recall(\n\t\tpost_preds,\n\t\tdecoded_labels\n\t)\n\tf1_raw =  (2 * raw_acc[0] * raw_acc[1]) / (raw_acc[0] + raw_acc[1])\n\tf1_post = (2 * post_acc[0] * post_acc[1]) / (post_acc[0] + post_acc[1])\n\n\treturn {\n\t\t\"pair_accuracy_raw_precision\": raw_acc[0],\n\t\t\"pair_accuracy_raw_recall\": raw_acc[1],\n\t\t\"pair_accuracy_raw_f1\": f1_raw,\n\t\t\"pair_accuracy_post_precision\": post_acc[0],\n\t\t\"pair_accuracy_post_recall\": post_acc[1],\n\t\t\"pair_accuracy_post_f1\": f1_post,\n\t\t\"stats_postprocessing\": stats,\n\t}","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-15T19:22:11.865457Z","iopub.execute_input":"2026-01-15T19:22:11.866263Z","iopub.status.idle":"2026-01-15T19:22:12.387567Z","shell.execute_reply.started":"2026-01-15T19:22:11.866230Z","shell.execute_reply":"2026-01-15T19:22:12.386991Z"}},"outputs":[],"execution_count":17},{"cell_type":"markdown","source":"## Define Training Arguments and Trainer\n\n### Subtask:\nSet up training arguments including parameters like learning rate, number of epochs, batch size, and evaluation strategy. The `report_to` argument will be updated to exclude 'wandb'. Utilize the `Trainer` class from the `transformers` library for simplified training management.\n","metadata":{"id":"0e56ac9e"}},{"cell_type":"code","source":"from transformers import Seq2SeqTrainingArguments, Seq2SeqTrainer\nimport torch\n\n# Define output directory\noutput_dir = f'./resultst{MODEL_NAME}'\n\n# Define TrainingArguments\ntraining_args = Seq2SeqTrainingArguments(\n    output_dir=output_dir,\n    num_train_epochs=EPOCHS,\n    per_device_train_batch_size=BATCH_SIZE,\n    per_device_eval_batch_size=BATCH_SIZE,\n    warmup_steps=500,\n    weight_decay=0.01,\n    logging_dir='./logs',\n    logging_steps=10,\n    eval_strategy='epoch',\n    save_strategy='best',#'no'\n    metric_for_best_model='pair_accuracy_raw_f1',\n    save_total_limit=2,\n    seed=42,  # Ensure consistent shuffling\n    predict_with_generate=True,\n    report_to=[], # Exclude wandb and other reporting services\n    fp16=torch.cuda.is_available() # Enable FP16 if a GPU is available\n)\n\n# Instantiate the Trainer\ntrainer = Seq2SeqTrainer(\n    model=model,\n    args=training_args,\n    train_dataset=train_dataset,\n    eval_dataset=eval_dataset,\n    tokenizer=tokenizer,\n    compute_metrics=compute_metrics,\n    data_collator=data_collator,\n)\n\nprint(\"TrainingArguments and Trainer initialized successfully.\")\nprint(\"Training Arguments:\", training_args)\nprint(\"Trainer instance:\", trainer)","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"6c09e940","outputId":"a0877bc0-f57c-4c4b-b4fa-fc2796310cf0","trusted":true,"execution":{"iopub.status.busy":"2026-01-15T19:15:43.581926Z","iopub.execute_input":"2026-01-15T19:15:43.582171Z","iopub.status.idle":"2026-01-15T19:15:45.435056Z","shell.execute_reply.started":"2026-01-15T19:15:43.582148Z","shell.execute_reply":"2026-01-15T19:15:45.434097Z"}},"outputs":[{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m/tmp/ipykernel_55/1396534903.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     32\u001b[0m     \u001b[0meval_dataset\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0meval_dataset\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m     \u001b[0mtokenizer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtokenizer\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 34\u001b[0;31m     \u001b[0mcompute_metrics\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcompute_metrics\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     35\u001b[0m     \u001b[0mdata_collator\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdata_collator\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m )\n","\u001b[0;31mNameError\u001b[0m: name 'compute_metrics' is not defined"],"ename":"NameError","evalue":"name 'compute_metrics' is not defined","output_type":"error"}],"execution_count":7},{"cell_type":"markdown","source":"## Training","metadata":{}},{"cell_type":"code","source":"print(\"Starting model training...\")\ntrainer.train()","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":657},"id":"38497c3a","outputId":"ff6c8e20-0980-4ba1-a7bb-459604929df2","trusted":true,"execution":{"iopub.status.busy":"2026-01-15T10:19:40.800672Z","iopub.execute_input":"2026-01-15T10:19:40.800982Z","iopub.status.idle":"2026-01-15T17:57:55.161480Z","shell.execute_reply.started":"2026-01-15T10:19:40.800954Z","shell.execute_reply":"2026-01-15T17:57:55.160853Z"}},"outputs":[{"name":"stdout","text":"Starting model training...\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.12/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='16075' max='16075' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [16075/16075 7:38:09, Epoch 25/25]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Epoch</th>\n      <th>Training Loss</th>\n      <th>Validation Loss</th>\n      <th>Pair Accuracy Raw Precision</th>\n      <th>Pair Accuracy Raw Recall</th>\n      <th>Pair Accuracy Raw F1</th>\n      <th>Pair Accuracy Post Precision</th>\n      <th>Pair Accuracy Post Recall</th>\n      <th>Pair Accuracy Post F1</th>\n      <th>Stats Postprocessing</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>1</td>\n      <td>0.015800</td>\n      <td>0.011360</td>\n      <td>0.507527</td>\n      <td>0.406663</td>\n      <td>0.451531</td>\n      <td>0.507527</td>\n      <td>0.406663</td>\n      <td>0.451531</td>\n      <td>{'aspect_case': 0, 'opinion_case': 0, 'opinion_negation': 0}</td>\n    </tr>\n    <tr>\n      <td>2</td>\n      <td>0.011400</td>\n      <td>0.008073</td>\n      <td>0.592639</td>\n      <td>0.545663</td>\n      <td>0.568182</td>\n      <td>0.592639</td>\n      <td>0.545663</td>\n      <td>0.568182</td>\n      <td>{'aspect_case': 0, 'opinion_case': 0, 'opinion_negation': 0}</td>\n    </tr>\n    <tr>\n      <td>3</td>\n      <td>0.009700</td>\n      <td>0.007382</td>\n      <td>0.614663</td>\n      <td>0.601953</td>\n      <td>0.608241</td>\n      <td>0.614663</td>\n      <td>0.601953</td>\n      <td>0.608241</td>\n      <td>{'aspect_case': 0, 'opinion_case': 0, 'opinion_negation': 0}</td>\n    </tr>\n    <tr>\n      <td>4</td>\n      <td>0.007400</td>\n      <td>0.006696</td>\n      <td>0.655748</td>\n      <td>0.609420</td>\n      <td>0.631736</td>\n      <td>0.655748</td>\n      <td>0.609420</td>\n      <td>0.631736</td>\n      <td>{'aspect_case': 0, 'opinion_case': 0, 'opinion_negation': 0}</td>\n    </tr>\n    <tr>\n      <td>5</td>\n      <td>0.005300</td>\n      <td>0.006596</td>\n      <td>0.666256</td>\n      <td>0.621482</td>\n      <td>0.643091</td>\n      <td>0.666256</td>\n      <td>0.621482</td>\n      <td>0.643091</td>\n      <td>{'aspect_case': 0, 'opinion_case': 0, 'opinion_negation': 0}</td>\n    </tr>\n    <tr>\n      <td>6</td>\n      <td>0.005100</td>\n      <td>0.006520</td>\n      <td>0.657625</td>\n      <td>0.626651</td>\n      <td>0.641765</td>\n      <td>0.657625</td>\n      <td>0.626651</td>\n      <td>0.641765</td>\n      <td>{'aspect_case': 0, 'opinion_case': 0, 'opinion_negation': 0}</td>\n    </tr>\n    <tr>\n      <td>7</td>\n      <td>0.004400</td>\n      <td>0.006333</td>\n      <td>0.677946</td>\n      <td>0.644457</td>\n      <td>0.660777</td>\n      <td>0.677946</td>\n      <td>0.644457</td>\n      <td>0.660777</td>\n      <td>{'aspect_case': 0, 'opinion_case': 0, 'opinion_negation': 0}</td>\n    </tr>\n    <tr>\n      <td>8</td>\n      <td>0.004700</td>\n      <td>0.006236</td>\n      <td>0.681628</td>\n      <td>0.654222</td>\n      <td>0.667644</td>\n      <td>0.681628</td>\n      <td>0.654222</td>\n      <td>0.667644</td>\n      <td>{'aspect_case': 0, 'opinion_case': 0, 'opinion_negation': 0}</td>\n    </tr>\n    <tr>\n      <td>9</td>\n      <td>0.002900</td>\n      <td>0.006678</td>\n      <td>0.672792</td>\n      <td>0.651924</td>\n      <td>0.662194</td>\n      <td>0.672792</td>\n      <td>0.651924</td>\n      <td>0.662194</td>\n      <td>{'aspect_case': 0, 'opinion_case': 0, 'opinion_negation': 0}</td>\n    </tr>\n    <tr>\n      <td>10</td>\n      <td>0.002600</td>\n      <td>0.006945</td>\n      <td>0.666085</td>\n      <td>0.657668</td>\n      <td>0.661850</td>\n      <td>0.666085</td>\n      <td>0.657668</td>\n      <td>0.661850</td>\n      <td>{'aspect_case': 0, 'opinion_case': 0, 'opinion_negation': 0}</td>\n    </tr>\n    <tr>\n      <td>11</td>\n      <td>0.002100</td>\n      <td>0.007036</td>\n      <td>0.667058</td>\n      <td>0.652499</td>\n      <td>0.659698</td>\n      <td>0.667058</td>\n      <td>0.652499</td>\n      <td>0.659698</td>\n      <td>{'aspect_case': 0, 'opinion_case': 0, 'opinion_negation': 0}</td>\n    </tr>\n    <tr>\n      <td>12</td>\n      <td>0.002400</td>\n      <td>0.007270</td>\n      <td>0.691150</td>\n      <td>0.659391</td>\n      <td>0.674897</td>\n      <td>0.691150</td>\n      <td>0.659391</td>\n      <td>0.674897</td>\n      <td>{'aspect_case': 0, 'opinion_case': 0, 'opinion_negation': 0}</td>\n    </tr>\n    <tr>\n      <td>13</td>\n      <td>0.002500</td>\n      <td>0.007464</td>\n      <td>0.681845</td>\n      <td>0.662263</td>\n      <td>0.671911</td>\n      <td>0.681845</td>\n      <td>0.662263</td>\n      <td>0.671911</td>\n      <td>{'aspect_case': 0, 'opinion_case': 0, 'opinion_negation': 0}</td>\n    </tr>\n    <tr>\n      <td>14</td>\n      <td>0.001400</td>\n      <td>0.007483</td>\n      <td>0.677438</td>\n      <td>0.662263</td>\n      <td>0.669765</td>\n      <td>0.677438</td>\n      <td>0.662263</td>\n      <td>0.669765</td>\n      <td>{'aspect_case': 0, 'opinion_case': 0, 'opinion_negation': 0}</td>\n    </tr>\n    <tr>\n      <td>15</td>\n      <td>0.001400</td>\n      <td>0.007678</td>\n      <td>0.685901</td>\n      <td>0.662263</td>\n      <td>0.673875</td>\n      <td>0.685901</td>\n      <td>0.662263</td>\n      <td>0.673875</td>\n      <td>{'aspect_case': 0, 'opinion_case': 0, 'opinion_negation': 0}</td>\n    </tr>\n    <tr>\n      <td>16</td>\n      <td>0.001700</td>\n      <td>0.007701</td>\n      <td>0.690349</td>\n      <td>0.669730</td>\n      <td>0.679883</td>\n      <td>0.690349</td>\n      <td>0.669730</td>\n      <td>0.679883</td>\n      <td>{'aspect_case': 0, 'opinion_case': 0, 'opinion_negation': 0}</td>\n    </tr>\n    <tr>\n      <td>17</td>\n      <td>0.002100</td>\n      <td>0.007951</td>\n      <td>0.684891</td>\n      <td>0.669156</td>\n      <td>0.676932</td>\n      <td>0.684891</td>\n      <td>0.669156</td>\n      <td>0.676932</td>\n      <td>{'aspect_case': 0, 'opinion_case': 0, 'opinion_negation': 0}</td>\n    </tr>\n    <tr>\n      <td>18</td>\n      <td>0.001200</td>\n      <td>0.008235</td>\n      <td>0.682193</td>\n      <td>0.664561</td>\n      <td>0.673262</td>\n      <td>0.682193</td>\n      <td>0.664561</td>\n      <td>0.673262</td>\n      <td>{'aspect_case': 0, 'opinion_case': 0, 'opinion_negation': 0}</td>\n    </tr>\n    <tr>\n      <td>19</td>\n      <td>0.001100</td>\n      <td>0.008102</td>\n      <td>0.688915</td>\n      <td>0.663986</td>\n      <td>0.676221</td>\n      <td>0.688915</td>\n      <td>0.663986</td>\n      <td>0.676221</td>\n      <td>{'aspect_case': 0, 'opinion_case': 0, 'opinion_negation': 0}</td>\n    </tr>\n    <tr>\n      <td>20</td>\n      <td>0.001100</td>\n      <td>0.008298</td>\n      <td>0.691801</td>\n      <td>0.663986</td>\n      <td>0.677608</td>\n      <td>0.691801</td>\n      <td>0.663986</td>\n      <td>0.677608</td>\n      <td>{'aspect_case': 0, 'opinion_case': 0, 'opinion_negation': 0}</td>\n    </tr>\n    <tr>\n      <td>21</td>\n      <td>0.000900</td>\n      <td>0.008484</td>\n      <td>0.682624</td>\n      <td>0.663412</td>\n      <td>0.672881</td>\n      <td>0.682624</td>\n      <td>0.663412</td>\n      <td>0.672881</td>\n      <td>{'aspect_case': 0, 'opinion_case': 0, 'opinion_negation': 0}</td>\n    </tr>\n    <tr>\n      <td>22</td>\n      <td>0.001000</td>\n      <td>0.008582</td>\n      <td>0.683284</td>\n      <td>0.669156</td>\n      <td>0.676146</td>\n      <td>0.683284</td>\n      <td>0.669156</td>\n      <td>0.676146</td>\n      <td>{'aspect_case': 0, 'opinion_case': 0, 'opinion_negation': 0}</td>\n    </tr>\n    <tr>\n      <td>23</td>\n      <td>0.000600</td>\n      <td>0.008656</td>\n      <td>0.689941</td>\n      <td>0.669730</td>\n      <td>0.679685</td>\n      <td>0.689941</td>\n      <td>0.669730</td>\n      <td>0.679685</td>\n      <td>{'aspect_case': 0, 'opinion_case': 0, 'opinion_negation': 0}</td>\n    </tr>\n    <tr>\n      <td>24</td>\n      <td>0.001200</td>\n      <td>0.008700</td>\n      <td>0.693720</td>\n      <td>0.672602</td>\n      <td>0.682998</td>\n      <td>0.693720</td>\n      <td>0.672602</td>\n      <td>0.682998</td>\n      <td>{'aspect_case': 0, 'opinion_case': 0, 'opinion_negation': 0}</td>\n    </tr>\n    <tr>\n      <td>25</td>\n      <td>0.000800</td>\n      <td>0.008743</td>\n      <td>0.692444</td>\n      <td>0.673751</td>\n      <td>0.682969</td>\n      <td>0.692444</td>\n      <td>0.673751</td>\n      <td>0.682969</td>\n      <td>{'aspect_case': 0, 'opinion_case': 0, 'opinion_negation': 0}</td>\n    </tr>\n  </tbody>\n</table><p>"},"metadata":{}},{"name":"stderr","text":"/usr/local/lib/python3.12/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n/usr/local/lib/python3.12/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n/usr/local/lib/python3.12/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n/usr/local/lib/python3.12/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n/usr/local/lib/python3.12/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n/usr/local/lib/python3.12/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n/usr/local/lib/python3.12/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n/usr/local/lib/python3.12/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n/usr/local/lib/python3.12/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n/usr/local/lib/python3.12/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n","output_type":"stream"},{"execution_count":8,"output_type":"execute_result","data":{"text/plain":"TrainOutput(global_step=16075, training_loss=0.09570862481696459, metrics={'train_runtime': 27493.1874, 'train_samples_per_second': 4.671, 'train_steps_per_second': 0.585, 'total_flos': 7.8205417095168e+16, 'train_loss': 0.09570862481696459, 'epoch': 25.0})"},"metadata":{}}],"execution_count":8},{"cell_type":"code","source":"trainer.save_model(MODEL_NAME)","metadata":{"id":"WVygcUHs3gTE","trusted":true,"execution":{"iopub.status.busy":"2026-01-15T17:57:55.162591Z","iopub.execute_input":"2026-01-15T17:57:55.162900Z","iopub.status.idle":"2026-01-15T17:57:56.724919Z","shell.execute_reply.started":"2026-01-15T17:57:55.162873Z","shell.execute_reply":"2026-01-15T17:57:56.724349Z"}},"outputs":[],"execution_count":9},{"cell_type":"code","source":"#!zip /kaggle/working/model.zip /kaggle/working/model","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-15T17:57:56.726807Z","iopub.execute_input":"2026-01-15T17:57:56.727058Z","iopub.status.idle":"2026-01-15T17:57:56.730351Z","shell.execute_reply.started":"2026-01-15T17:57:56.727035Z","shell.execute_reply":"2026-01-15T17:57:56.729770Z"}},"outputs":[],"execution_count":10},{"cell_type":"code","source":"#rm -rf /content/results","metadata":{"id":"spgQdVVbHA_w","trusted":true,"execution":{"iopub.status.busy":"2026-01-15T17:57:56.731013Z","iopub.execute_input":"2026-01-15T17:57:56.731281Z","iopub.status.idle":"2026-01-15T17:57:56.745784Z","shell.execute_reply.started":"2026-01-15T17:57:56.731226Z","shell.execute_reply":"2026-01-15T17:57:56.745248Z"}},"outputs":[],"execution_count":11},{"cell_type":"markdown","source":"## Eval","metadata":{}},{"cell_type":"code","source":"import numpy as np\nfrom transformers import EvalPrediction\n\nprint(\"Evaluating model performance...\")\n# Make predictions on the evaluation dataset\n# Added predict_with_generate=True to ensure proper token ID generation\npredictions_output = trainer.predict(eval_dataset)\n\n# Get the predicted token IDs (no argmax needed here as predict_with_generate handles it)\npredicted_ids = predictions_output.predictions\nlabel_ids = predictions_output.label_ids\n\n# Decode the predicted token IDs\npredicted_ids = np.where(predicted_ids != -100, predicted_ids, tokenizer.pad_token_id)\ndecoded_predictions = label_ids_to_text(predicted_ids, tokenizer)\n\ndecoded_labels = label_ids_to_text(label_ids, tokenizer)\n\n# Print a few examples for visual inspection\nprint(\"\\n--- Sample Predictions vs. True Labels ---\")\nfor i in range(min(5, len(eval_dataset))): # Print up to 5 examples\n    original_text = eval_dataset[i]['Text']\n    true_target = decoded_labels[i]\n    predicted_target = decoded_predictions[i]\n\n    print(f\"\\nOriginal Text: {original_text}\")\n    print(f\"True Target:   {true_target}\")\n    print(f\"Predicted:     {predicted_target}\")\n    print(\"---\")\n\nprint(compute_metrics((predicted_ids, label_ids)))\nprint(\"\\nEvaluation complete.\")","metadata":{"id":"8DrXSHvuILry","trusted":true,"execution":{"iopub.status.busy":"2026-01-15T17:57:56.746606Z","iopub.execute_input":"2026-01-15T17:57:56.746864Z","iopub.status.idle":"2026-01-15T18:01:01.549701Z","shell.execute_reply.started":"2026-01-15T17:57:56.746841Z","shell.execute_reply":"2026-01-15T18:01:01.548921Z"}},"outputs":[{"name":"stdout","text":"Evaluating model performance...\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":""},"metadata":{}},{"name":"stdout","text":"\n--- Sample Predictions vs. True Labels ---\n\nOriginal Text: screen display is bright and has excellent graphics .\nTrue Target:   screen display#bright|graphics#excellent|\nPredicted:     screen display#bright|screen display#excellent|\n---\n\nOriginal Text: would definitely buy this again if i needed to do so .\nTrue Target:   NULL#NULL|\nPredicted:     NULL#NULL|\n---\n\nOriginal Text: this laptop ' s construction is cheap and flimsy , the battery is not removable and the back case is nearly impossible to take off without damaging it .\nTrue Target:   laptop ' s construction#cheap|laptop ' s construction#flimsy|battery#not removable|back case#NULL|\nPredicted:     laptop ' s construction#cheap|laptop ' s construction#f\n---\n\nOriginal Text: i ' ve found the touch screen is pretty handy .\nTrue Target:   touch screen#pretty handy|\nPredicted:     touch screen#pretty handy|\n---\n\nOriginal Text: up date per may 13 / 2018 about two months ago , the charger wont work .\nTrue Target:   charger#NULL|\nPredicted:     charger#NULL|\n---\n{'pair_accuracy_raw_precision': 0.692443919716647, 'pair_accuracy_raw_recall': 0.6737507179781734, 'pair_accuracy_raw_f1': 0.6829694323144104, 'pair_accuracy_post_precision': 0.692443919716647, 'pair_accuracy_post_recall': 0.6737507179781734, 'pair_accuracy_post_f1': 0.6829694323144104, 'stats_postprocessing': {'aspect_case': 0, 'opinion_case': 0, 'opinion_negation': 0}}\n\nEvaluation complete.\n","output_type":"stream"}],"execution_count":12},{"cell_type":"code","source":"# Load best checkpoint\nMODEL_CHECKPOINT_BEST = '/kaggle/working/resultstmodel_t5_25/checkpoint-15432'\n# Initialize the tokenizer\ntokenizer = AutoTokenizer.from_pretrained(MODEL_CHECKPOINT)\nprint(f\"Tokenizer '{MODEL_CHECKPOINT}' loaded successfully.\")\n\n# Initialize the Seq2Seq model\nmodel = AutoModelForSeq2SeqLM.from_pretrained(MODEL_CHECKPOINT_BEST)\nprint(f\"Model '{MODEL_CHECKPOINT_BEST}' loaded successfully.\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-15T19:17:42.942881Z","iopub.execute_input":"2026-01-15T19:17:42.943603Z","iopub.status.idle":"2026-01-15T19:17:43.510371Z","shell.execute_reply.started":"2026-01-15T19:17:42.943570Z","shell.execute_reply":"2026-01-15T19:17:43.509774Z"}},"outputs":[{"name":"stdout","text":"Tokenizer '/kaggle/working/model_t5_25' loaded successfully.\nModel '/kaggle/working/resultstmodel_t5_25/checkpoint-15432' loaded successfully.\n","output_type":"stream"}],"execution_count":12},{"cell_type":"code","source":"import gc\ngc.collect()\ntorch.cuda.empty_cache()\nprint(torch.cuda.memory_allocated())\nprint(torch.cuda.memory_cached())","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-15T19:17:46.195066Z","iopub.execute_input":"2026-01-15T19:17:46.195667Z","iopub.status.idle":"2026-01-15T19:17:46.572442Z","shell.execute_reply.started":"2026-01-15T19:17:46.195626Z","shell.execute_reply":"2026-01-15T19:17:46.571710Z"}},"outputs":[{"name":"stdout","text":"0\n0\n","output_type":"stream"},{"name":"stderr","text":"/tmp/ipykernel_55/1632861553.py:5: FutureWarning: `torch.cuda.memory_cached` has been renamed to `torch.cuda.memory_reserved`\n  print(torch.cuda.memory_cached())\n","output_type":"stream"}],"execution_count":13},{"cell_type":"code","source":"import numpy as np\nmodel.eval()\nmodel.to('cuda')\ngenerated_ids = []\nimport gc, tqdm\nstep = 20\nfor i in tqdm.trange(0, len(test_dataset), step):\n    generated_ids.append(model.generate(\n        input_ids=torch.tensor(list(test_dataset['input_ids'][i:i+step]), device='cuda'),  # Tokenized source inputs for the encoder\n        attention_mask=torch.tensor(list(test_dataset['attention_mask'][i:i+step]), device='cuda'),  # Tokenized source inputs for the encoder\n        num_beams=4,  # Optionally, use beam search\n    ).cpu())\n    gc.collect()\n    torch.cuda.empty_cache()\nimport torch\n\n# Find the maximum sequence length across all tensors\nmax_seq_len = max([a.shape[1] for a in generated_ids])  # Use shape[1] for the sequence length\n\n# Pad the sequences to the maximum sequence length\npadded_predictions_test = [\n    torch.cat([a, torch.full((a.shape[0], max_seq_len - a.shape[1]), tokenizer.pad_token_id)], dim=1) if a.shape[1] < max_seq_len else a\n    for a in generated_ids\n]\npadded_predictions_test = np.vstack(padded_predictions_test)\nprint(padded_predictions_test.shape)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-15T19:17:49.313881Z","iopub.execute_input":"2026-01-15T19:17:49.314642Z","iopub.status.idle":"2026-01-15T19:20:30.739317Z","shell.execute_reply.started":"2026-01-15T19:17:49.314599Z","shell.execute_reply":"2026-01-15T19:20:30.738368Z"}},"outputs":[{"name":"stderr","text":"100%|██████████| 60/60 [02:41<00:00,  2.68s/it]\n","output_type":"stream"},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m/tmp/ipykernel_55/81310241.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     22\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0ma\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mgenerated_ids\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m ]\n\u001b[0;32m---> 24\u001b[0;31m \u001b[0mpadded_predictions_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvstack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpadded_predictions_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     25\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpadded_predictions_test\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mNameError\u001b[0m: name 'np' is not defined"],"ename":"NameError","evalue":"name 'np' is not defined","output_type":"error"}],"execution_count":14},{"cell_type":"code","source":"#predictions_output_test = trainer.predict(test_dataset)\npredicted_ids_test = padded_predictions_test#predictions_output_test.predictions\nimport numpy as np\n# Replace -100 with tokenizer.pad_token_id before decoding\n# This is a safeguard if -100 somehow still appears, though predict_with_generate=True should prevent it\ndata_test['Task2OutRaw'] = label_ids_to_text(predicted_ids_test, tokenizer)\ndata_test['Quadruplets'] = data_test['Task2OutRaw'].apply(raw_text_to_quads)\nif not os.path.exists(f'/kaggle/working/preds/{MODEL_NAME}'):\n    os.mkdir(f'/kaggle/working/preds/{MODEL_NAME}')\nwith open(f'/kaggle/working/preds/{MODEL_NAME}/test_pred_nopostprocess.jsonl', 'w') as f:\n    f.write(data_test.to_json(lines=True, orient='records'))\nstats = {'aspect_case': 0, 'opinion_case': 0, 'opinion_negation': 0}\ndata_test = postprocess(data_test, stats)\ndisplay(data_test)\nwith open(f'/kaggle/working/preds/{MODEL_NAME}/test_pred.jsonl', 'w') as f:\n    f.write(data_test.to_json(lines=True, orient='records'))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-15T19:22:16.416005Z","iopub.execute_input":"2026-01-15T19:22:16.416658Z","iopub.status.idle":"2026-01-15T19:22:16.538855Z","shell.execute_reply.started":"2026-01-15T19:22:16.416627Z","shell.execute_reply":"2026-01-15T19:22:16.538230Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"                        ID  \\\n0    lap26_aspect_va_dev_1   \n1    lap26_aspect_va_dev_2   \n2    lap26_aspect_va_dev_3   \n3    lap26_aspect_va_dev_4   \n4    lap26_aspect_va_dev_5   \n..                     ...   \n195    rest26_asqp_dev_196   \n196    rest26_asqp_dev_197   \n197    rest26_asqp_dev_198   \n198    rest26_asqp_dev_199   \n199    rest26_asqp_dev_200   \n\n                                                                                       Text  \\\n0                                                           The touchscreen works very well   \n1                                                                I am so disappointed in HP   \n2                                         The keyboard is big enough to use for real typing   \n3                                                                    I like the screen size   \n4                                                   Lenovo is my favorite brand of computer   \n..                                                                                      ...   \n195                                                       The food was good , but not great   \n196                                  Their butter cookies are awesome -absolutely love them   \n197                                The variety of boba tea that they have is also very good   \n198  The service was great the workers were really nice and patient with me haha indecisive   \n199                               Prices are somewhat reasonable and the atmosphere is good   \n\n            Aspect                                         Task2OutRaw  \\\n0    [touchscreen]                              touchscreen#very well|   \n1             [HP]                                 HP#so disappointed|   \n2       [keyboard]                                       keyboard#big|   \n3    [screen size]                                   screen size#like|   \n4         [Lenovo]                                    Lenovo#favorite|   \n..             ...                                                 ...   \n195            NaN                           food#not great|food#good|   \n196            NaN         butter cookies#awesome|butter cookies#love|   \n197            NaN                                 boba tea#very good|   \n198            NaN  service#great|workers#really nice|workers#patient|   \n199            NaN           NULL#somewhat reasonable|atmosphere#good|   \n\n                                                                                                                                   Quadruplets  \n0                                                                                          [{'Aspect': 'touchscreen', 'Opinion': 'very well'}]  \n1                                                                                             [{'Aspect': 'HP', 'Opinion': 'so disappointed'}]  \n2                                                                                                   [{'Aspect': 'keyboard', 'Opinion': 'big'}]  \n3                                                                                               [{'Aspect': 'screen size', 'Opinion': 'like'}]  \n4                                                                                                [{'Aspect': 'Lenovo', 'Opinion': 'favorite'}]  \n..                                                                                                                                         ...  \n195                                                        [{'Aspect': 'food', 'Opinion': 'not great'}, {'Aspect': 'food', 'Opinion': 'good'}]  \n196                                      [{'Aspect': 'butter cookies', 'Opinion': 'awesome'}, {'Aspect': 'butter cookies', 'Opinion': 'love'}]  \n197                                                                                           [{'Aspect': 'boba tea', 'Opinion': 'very good'}]  \n198  [{'Aspect': 'service', 'Opinion': 'great'}, {'Aspect': 'workers', 'Opinion': 'really nice'}, {'Aspect': 'workers', 'Opinion': 'patient'}]  \n199                                        [{'Aspect': 'NULL', 'Opinion': 'somewhat reasonable'}, {'Aspect': 'atmosphere', 'Opinion': 'good'}]  \n\n[1200 rows x 5 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>ID</th>\n      <th>Text</th>\n      <th>Aspect</th>\n      <th>Task2OutRaw</th>\n      <th>Quadruplets</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>lap26_aspect_va_dev_1</td>\n      <td>The touchscreen works very well</td>\n      <td>[touchscreen]</td>\n      <td>touchscreen#very well|</td>\n      <td>[{'Aspect': 'touchscreen', 'Opinion': 'very well'}]</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>lap26_aspect_va_dev_2</td>\n      <td>I am so disappointed in HP</td>\n      <td>[HP]</td>\n      <td>HP#so disappointed|</td>\n      <td>[{'Aspect': 'HP', 'Opinion': 'so disappointed'}]</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>lap26_aspect_va_dev_3</td>\n      <td>The keyboard is big enough to use for real typing</td>\n      <td>[keyboard]</td>\n      <td>keyboard#big|</td>\n      <td>[{'Aspect': 'keyboard', 'Opinion': 'big'}]</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>lap26_aspect_va_dev_4</td>\n      <td>I like the screen size</td>\n      <td>[screen size]</td>\n      <td>screen size#like|</td>\n      <td>[{'Aspect': 'screen size', 'Opinion': 'like'}]</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>lap26_aspect_va_dev_5</td>\n      <td>Lenovo is my favorite brand of computer</td>\n      <td>[Lenovo]</td>\n      <td>Lenovo#favorite|</td>\n      <td>[{'Aspect': 'Lenovo', 'Opinion': 'favorite'}]</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>195</th>\n      <td>rest26_asqp_dev_196</td>\n      <td>The food was good , but not great</td>\n      <td>NaN</td>\n      <td>food#not great|food#good|</td>\n      <td>[{'Aspect': 'food', 'Opinion': 'not great'}, {'Aspect': 'food', 'Opinion': 'good'}]</td>\n    </tr>\n    <tr>\n      <th>196</th>\n      <td>rest26_asqp_dev_197</td>\n      <td>Their butter cookies are awesome -absolutely love them</td>\n      <td>NaN</td>\n      <td>butter cookies#awesome|butter cookies#love|</td>\n      <td>[{'Aspect': 'butter cookies', 'Opinion': 'awesome'}, {'Aspect': 'butter cookies', 'Opinion': 'love'}]</td>\n    </tr>\n    <tr>\n      <th>197</th>\n      <td>rest26_asqp_dev_198</td>\n      <td>The variety of boba tea that they have is also very good</td>\n      <td>NaN</td>\n      <td>boba tea#very good|</td>\n      <td>[{'Aspect': 'boba tea', 'Opinion': 'very good'}]</td>\n    </tr>\n    <tr>\n      <th>198</th>\n      <td>rest26_asqp_dev_199</td>\n      <td>The service was great the workers were really nice and patient with me haha indecisive</td>\n      <td>NaN</td>\n      <td>service#great|workers#really nice|workers#patient|</td>\n      <td>[{'Aspect': 'service', 'Opinion': 'great'}, {'Aspect': 'workers', 'Opinion': 'really nice'}, {'Aspect': 'workers', 'Opinion': 'patient'}]</td>\n    </tr>\n    <tr>\n      <th>199</th>\n      <td>rest26_asqp_dev_200</td>\n      <td>Prices are somewhat reasonable and the atmosphere is good</td>\n      <td>NaN</td>\n      <td>NULL#somewhat reasonable|atmosphere#good|</td>\n      <td>[{'Aspect': 'NULL', 'Opinion': 'somewhat reasonable'}, {'Aspect': 'atmosphere', 'Opinion': 'good'}]</td>\n    </tr>\n  </tbody>\n</table>\n<p>1200 rows × 5 columns</p>\n</div>"},"metadata":{}}],"execution_count":18}]}